{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "287a4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "bdf05678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "os.chdir('/home/ec2-user/ecg-autoregressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "60b873af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/home/ec2-user/ecg-autoregressive/data.py'>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data\n",
    "import waveform_embedder\n",
    "importlib.reload(waveform_embedder)\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "cb0d0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vit_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "81cd16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = json.loads(open(os.path.join('models', model_name, 'hyperparameters.json')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5a479708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'window_size': 256,\n",
       " 'latent_dim': 16,\n",
       " 'num_transformer_blocks': 1,\n",
       " 'dim_feedforward': 256,\n",
       " 'encoder_hidden_dim': 64,\n",
       " 'num_heads': 4,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 64,\n",
       " 'device': 'cuda'}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "166631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = hyperparams['window_size']\n",
    "patch_size = hyperparams['latent_dim']\n",
    "num_transformer_blocks = hyperparams['num_transformer_blocks']\n",
    "encoder_hidden_dim = hyperparams['encoder_hidden_dim']\n",
    "dim_feedforward = hyperparams['dim_feedforward']\n",
    "num_heads = hyperparams['num_heads']\n",
    "device = 'cuda'\n",
    "model_path = os.path.join('models', model_name, 'model.pth')\n",
    "\n",
    "#embedder = waveform_embedder.WaveformEmbedder(model_path, window_size, patch_size, num_transformer_blocks, encoder_hidden_dim, dim_feedforward, num_heads, device)\n",
    "\n",
    "embedder = waveform_embedder.ViTWaveformEmbedder(model_path, window_size, model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "408e6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21496192"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(embedder.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "329ed3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = data.HDF5DatasetKeras(data.H5_PATH, split_type='train', embedder=embedder, subsample=10, window_size=window_size)\n",
    "val_emb = data.HDF5DatasetKeras(data.H5_PATH, split_type='val', embedder=embedder, subsample=10, window_size=window_size)\n",
    "test_emb = data.HDF5DatasetKeras(data.H5_PATH, split_type='test', embedder=embedder, subsample=10, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7acedf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.HDF5DatasetKeras(data.H5_PATH, split_type='train', subsample=10, window_size=window_size)\n",
    "val = data.HDF5DatasetKeras(data.H5_PATH, split_type='val', subsample=10, window_size=window_size)\n",
    "test = data.HDF5DatasetKeras(data.H5_PATH, split_type='test', subsample=10, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "07df5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 256)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(train[0][0].shape)\n",
    "print(train[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ffe83707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 384)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "926dc9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "84559a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold your data\n",
    "X_train_emb, y_train_emb = [], []\n",
    "\n",
    "# Load training data\n",
    "for X_batch, y_batch in train_emb:\n",
    "    X_train_emb.append(X_batch)\n",
    "    y_train_emb.append(y_batch)\n",
    "    \n",
    "# Convert lists to arrays\n",
    "X_train_emb = np.concatenate(X_train_emb, axis=0)\n",
    "y_train_emb = np.concatenate(y_train_emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "510d097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_emb, y_val_emb = [], []\n",
    "for X_batch, y_batch in val_emb:\n",
    "    X_val_emb.append(X_batch)\n",
    "    y_val_emb.append(y_batch)\n",
    "\n",
    "X_val_emb = np.concatenate(X_val_emb, axis=0)\n",
    "y_val_emb = np.concatenate(y_val_emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ad31e283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 384)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a7a374bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "1e5c664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 is 77.25% of the samples [train]\n",
      "Class 0 is 62.50% of the samples [val]\n",
      "{0: 0.6472602739726028, 1: 2.197674418604651}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train_emb)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_emb)\n",
    "class_weight_dict = {class_label: weight for class_label, weight in zip(classes, class_weights)}\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = np.bincount(y_train_emb.astype(int))\n",
    "\n",
    "# Find the majority class and its percentage\n",
    "majority_class = np.argmax(class_counts)\n",
    "majority_class_percentage = (class_counts[majority_class] / len(y_train_emb)) * 100\n",
    "\n",
    "print(f'Class {majority_class} is {majority_class_percentage:.2f}% of the samples [train]')\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = np.bincount(y_val_emb.astype(int))\n",
    "\n",
    "# Find the majority class and its percentage\n",
    "majority_class = np.argmax(class_counts)\n",
    "majority_class_percentage = (class_counts[majority_class] / len(y_val_emb)) * 100\n",
    "\n",
    "print(f'Class {majority_class} is {majority_class_percentage:.2f}% of the samples [val]')\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8665d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 256)               98560     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148097 (578.50 KB)\n",
      "Trainable params: 148097 (578.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "60/60 [==============================] - 2s 7ms/step - loss: 2.1014 - accuracy: 0.6561 - auc_21: 0.5351 - val_loss: 0.7481 - val_accuracy: 0.6333 - val_auc_21: 0.5451\n",
      "Epoch 2/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0078 - accuracy: 0.6794 - auc_21: 0.5290 - val_loss: 0.6803 - val_accuracy: 0.6250 - val_auc_21: 0.5271\n",
      "Epoch 3/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8243 - accuracy: 0.6862 - auc_21: 0.5347 - val_loss: 0.6518 - val_accuracy: 0.6250 - val_auc_21: 0.5892\n",
      "Epoch 4/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.7201 - auc_21: 0.5806 - val_loss: 0.6343 - val_accuracy: 0.6292 - val_auc_21: 0.6528\n",
      "Epoch 5/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7354 - auc_21: 0.6008 - val_loss: 0.6362 - val_accuracy: 0.6250 - val_auc_21: 0.6553\n",
      "Epoch 6/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7587 - auc_21: 0.6333 - val_loss: 0.6344 - val_accuracy: 0.6333 - val_auc_21: 0.6490\n",
      "Epoch 7/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7741 - auc_21: 0.6819 - val_loss: 0.6314 - val_accuracy: 0.6292 - val_auc_21: 0.6867\n",
      "Epoch 8/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7794 - auc_21: 0.7148 - val_loss: 0.6229 - val_accuracy: 0.6375 - val_auc_21: 0.7062\n",
      "Epoch 9/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7910 - auc_21: 0.7410 - val_loss: 0.6132 - val_accuracy: 0.6500 - val_auc_21: 0.7236\n",
      "Epoch 10/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8058 - auc_21: 0.7713 - val_loss: 0.6069 - val_accuracy: 0.6667 - val_auc_21: 0.7159\n",
      "Epoch 11/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8148 - auc_21: 0.7991 - val_loss: 0.5859 - val_accuracy: 0.6833 - val_auc_21: 0.7310\n",
      "Epoch 12/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8365 - auc_21: 0.8263 - val_loss: 0.6347 - val_accuracy: 0.6500 - val_auc_21: 0.6842\n",
      "Epoch 13/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8429 - auc_21: 0.8535 - val_loss: 0.6411 - val_accuracy: 0.6542 - val_auc_21: 0.6855\n",
      "Epoch 14/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8481 - auc_21: 0.8453 - val_loss: 0.6864 - val_accuracy: 0.6083 - val_auc_21: 0.6970\n",
      "Epoch 15/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8688 - auc_21: 0.8916 - val_loss: 0.6429 - val_accuracy: 0.6833 - val_auc_21: 0.7180\n",
      "Epoch 16/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8677 - auc_21: 0.8982 - val_loss: 0.7010 - val_accuracy: 0.6708 - val_auc_21: 0.6847\n",
      "Epoch 17/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8915 - auc_21: 0.9162 - val_loss: 0.7341 - val_accuracy: 0.6708 - val_auc_21: 0.6650\n",
      "Epoch 18/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.9032 - auc_21: 0.9306 - val_loss: 0.8314 - val_accuracy: 0.6708 - val_auc_21: 0.6923\n",
      "Epoch 19/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9005 - auc_21: 0.9256 - val_loss: 0.7668 - val_accuracy: 0.6667 - val_auc_21: 0.6879\n",
      "Epoch 20/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9159 - auc_21: 0.9383 - val_loss: 0.9223 - val_accuracy: 0.6292 - val_auc_21: 0.6581\n",
      "Epoch 21/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9254 - auc_21: 0.9516 - val_loss: 0.8757 - val_accuracy: 0.6792 - val_auc_21: 0.6814\n",
      "Epoch 22/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9344 - auc_21: 0.9684 - val_loss: 1.0711 - val_accuracy: 0.6708 - val_auc_21: 0.6633\n",
      "Epoch 23/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9370 - auc_21: 0.9750 - val_loss: 0.9053 - val_accuracy: 0.6708 - val_auc_21: 0.7163\n",
      "Epoch 24/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9476 - auc_21: 0.9748 - val_loss: 1.1652 - val_accuracy: 0.6667 - val_auc_21: 0.6938\n",
      "Epoch 25/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9460 - auc_21: 0.9752 - val_loss: 0.9966 - val_accuracy: 0.6875 - val_auc_21: 0.7018\n",
      "Epoch 26/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9476 - auc_21: 0.9782 - val_loss: 1.2287 - val_accuracy: 0.6750 - val_auc_21: 0.6664\n",
      "Epoch 27/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9566 - auc_21: 0.9832 - val_loss: 1.1819 - val_accuracy: 0.6750 - val_auc_21: 0.6912\n",
      "Epoch 28/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9672 - auc_21: 0.9922 - val_loss: 1.8631 - val_accuracy: 0.6417 - val_auc_21: 0.6605\n",
      "Epoch 29/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9635 - auc_21: 0.9901 - val_loss: 1.4444 - val_accuracy: 0.6583 - val_auc_21: 0.6650\n",
      "Epoch 30/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9672 - auc_21: 0.9905 - val_loss: 1.4665 - val_accuracy: 0.6667 - val_auc_21: 0.6335\n",
      "Epoch 31/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9608 - auc_21: 0.9876 - val_loss: 1.5593 - val_accuracy: 0.6667 - val_auc_21: 0.6209\n",
      "Epoch 32/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9693 - auc_21: 0.9888 - val_loss: 1.5374 - val_accuracy: 0.6708 - val_auc_21: 0.6669\n",
      "Epoch 33/40\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9720 - auc_21: 0.9915 - val_loss: 1.4452 - val_accuracy: 0.6708 - val_auc_21: 0.6830\n",
      "Epoch 34/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9698 - auc_21: 0.9896 - val_loss: 1.4747 - val_accuracy: 0.6458 - val_auc_21: 0.6534\n",
      "Epoch 35/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9709 - auc_21: 0.9903 - val_loss: 1.3416 - val_accuracy: 0.6792 - val_auc_21: 0.6922\n",
      "Epoch 36/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9730 - auc_21: 0.9935 - val_loss: 1.1999 - val_accuracy: 0.6917 - val_auc_21: 0.7271\n",
      "Epoch 37/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9762 - auc_21: 0.9946 - val_loss: 1.5444 - val_accuracy: 0.6750 - val_auc_21: 0.6702\n",
      "Epoch 38/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9804 - auc_21: 0.9916 - val_loss: 1.8694 - val_accuracy: 0.6792 - val_auc_21: 0.6268\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9746 - auc_21: 0.9936 - val_loss: 1.6328 - val_accuracy: 0.6958 - val_auc_21: 0.6503\n",
      "Epoch 40/40\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9810 - auc_21: 0.9936 - val_loss: 2.1292 - val_accuracy: 0.6542 - val_auc_21: 0.6126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd77c483550>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(384,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=AdamW(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy', AUC()])\n",
    "#model.fit(X_train_emb, y_train_emb, epochs=15, validation_data=(X_val_emb, y_val_emb), class_weight=class_weight_dict)\n",
    "model.fit(X_train_emb, y_train_emb, epochs=40, validation_data=(X_val_emb, y_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6828fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1890, 2560)\n",
      "(1890,)\n",
      "(240, 2560)\n",
      "(240,)\n",
      "Class 0 is 77.25% of the samples\n",
      "Class 0 is 62.50% of the samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def reshape_and_load_data(dataloader):\n",
    "    X, y = [], []\n",
    "    for data, labels in dataloader:\n",
    "        reshaped_data = data.reshape(data.shape[0], -1)  # Reshape from (10, 10, 64) to (10, 640)\n",
    "        X.append(reshaped_data)\n",
    "        y.append(labels)\n",
    "        if reshaped_data.shape[0] != labels.shape[0]:\n",
    "            print('error with shapes')\n",
    "            print(reshaped_data.shape)\n",
    "            print(y.shape)\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    return X, y\n",
    "\n",
    "def print_class_representation(y):\n",
    "    class_counts = np.bincount(y.astype(int))\n",
    "    majority_class = np.argmax(class_counts)\n",
    "    majority_percentage = (class_counts[majority_class] / len(y)) * 100\n",
    "    print(f'Class {majority_class} is {majority_percentage:.2f}% of the samples')\n",
    "\n",
    "# Assuming `train` and `val` are your dataloaders\n",
    "X_train, y_train = reshape_and_load_data(train)\n",
    "X_val, y_val = reshape_and_load_data(val)\n",
    "\n",
    "# Print class representation\n",
    "print_class_representation(y_train)\n",
    "print_class_representation(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1e9b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95072daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "#        Dense(64, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Adjust based on your classification task\n",
    "    ])\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68502278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 2558, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 1279, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 1277, 32)          3104      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 638, 32)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 636, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 318, 32)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 10176)             0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 256)               2605312   \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2611905 (9.96 MB)\n",
      "Trainable params: 2611905 (9.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(1890, 2560)\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 3s 30ms/step - loss: 0.6904 - accuracy: 0.4836 - auc_15: 0.5589 - val_loss: 0.7110 - val_accuracy: 0.4583 - val_auc_15: 0.4211\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6770 - accuracy: 0.5312 - auc_15: 0.5962 - val_loss: 0.6992 - val_accuracy: 0.5458 - val_auc_15: 0.4556\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6575 - accuracy: 0.6534 - auc_15: 0.6693 - val_loss: 0.7167 - val_accuracy: 0.5042 - val_auc_15: 0.6044\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.6338 - accuracy: 0.6265 - auc_15: 0.7144 - val_loss: 0.7033 - val_accuracy: 0.6250 - val_auc_15: 0.6360\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.5827 - accuracy: 0.7212 - auc_15: 0.7882 - val_loss: 0.6723 - val_accuracy: 0.5792 - val_auc_15: 0.6349\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.5489 - accuracy: 0.7471 - auc_15: 0.8110 - val_loss: 0.6229 - val_accuracy: 0.5917 - val_auc_15: 0.6867\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5084 - accuracy: 0.7825 - auc_15: 0.8507 - val_loss: 0.6453 - val_accuracy: 0.6542 - val_auc_15: 0.6900\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.4794 - accuracy: 0.8021 - auc_15: 0.8714 - val_loss: 0.6234 - val_accuracy: 0.6417 - val_auc_15: 0.6905\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.4457 - accuracy: 0.8175 - auc_15: 0.8927 - val_loss: 0.6406 - val_accuracy: 0.6292 - val_auc_15: 0.6831\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.4321 - accuracy: 0.8243 - auc_15: 0.8978 - val_loss: 0.6622 - val_accuracy: 0.6125 - val_auc_15: 0.6730\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3912 - accuracy: 0.8503 - auc_15: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.6583 - val_auc_15: 0.6975\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.3700 - accuracy: 0.8587 - auc_15: 0.9319 - val_loss: 0.6417 - val_accuracy: 0.6792 - val_auc_15: 0.6871\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3629 - accuracy: 0.8603 - auc_15: 0.9331 - val_loss: 0.6452 - val_accuracy: 0.6625 - val_auc_15: 0.6902\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3214 - accuracy: 0.8820 - auc_15: 0.9532 - val_loss: 0.6790 - val_accuracy: 0.6500 - val_auc_15: 0.6634\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.3029 - accuracy: 0.8910 - auc_15: 0.9601 - val_loss: 0.6905 - val_accuracy: 0.6500 - val_auc_15: 0.6811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4d1c741a80>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "model = build_model((X_train.shape[1], 1))  # Adjust the input shape for 1D CNN\n",
    "model.summary()\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: weight for i, weight in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "# Reshape for 1D CNN, adding channel dimension\n",
    "#X_train = np.expand_dims(X_train, -1)\n",
    "#X_val = np.expand_dims(X_val, -1)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed8f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
